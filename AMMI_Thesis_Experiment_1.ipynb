{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMMI_Thesis_Experiment_1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R27O82HBmKt9",
        "colab_type": "text"
      },
      "source": [
        "# Training object detection model on my custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsOKkvVUPW-n",
        "colab_type": "text"
      },
      "source": [
        "## 1. DTECTRON2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHtwVY56kYAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Downloading data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')#\n",
        "#root_path = 'gdrive/My Drive/AMMI_project/object_detector'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIwnimpHeLSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Downloading data from my google drive\n",
        "!unzip -q /content/gdrive/My\\ Drive/AMMI_project/object_detector/data.zip -d dataset/\n",
        "#Downloading data from my google drive\n",
        "!unzip -q /content/gdrive/My\\ Drive/AMMI_project/object_detector/data2.zip -d dataset2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbqSKEGR-4kh",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6S5mCj-w1mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html >/dev/null\n",
        "!pip install cython pyyaml==5.1 >/dev/null\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI' >/dev/null\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "\n",
        "# install detectron2:\n",
        "!pip install detectron2==0.1.2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html >/dev/null\n",
        "\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "#from detectron2.data.datasets import register_pascal_voc\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga00CFdUXeq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'mydata'\n",
        "dirname = './dataset/data/'\n",
        "dirname2 = './dataset2/data2/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZUPhZSJdXKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from typing import List, Tuple, Union\n",
        "from fvcore.common.file_io import PathManager\n",
        "\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.structures import BoxMode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLhG55Esc2QJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "__all__ = [\"load_voc_instances\", \"register_pascal_voc\"]\n",
        "\n",
        "\n",
        "# fmt: off\n",
        "CLASS_NAMES = ('giraffe',\n",
        "                'person',\n",
        "                'zebra',\n",
        "                'elephant',\n",
        "                'impala',\n",
        "                'monkey',\n",
        "                'lion',\n",
        "                'leopard',\n",
        "                'crocodile',\n",
        "                'buffalo',\n",
        "                'hyna',\n",
        "                'bird',\n",
        "                'gorilla')\n",
        "# fmt: on\n",
        "\n",
        "def load_voc_instances(dirname: str, split: str, class_names: Union[List[str], Tuple[str, ...]]):\n",
        "    \"\"\"\n",
        "    Load Pascal VOC detection annotations to Detectron2 format.\n",
        "    Args:\n",
        "        dirname: Contain \"Annotations\", \"ImageSets\", \"JPEGImages\"\n",
        "        split (str): one of \"train\", \"test\", \"val\", \"trainval\"\n",
        "        class_names: list or tuple of class names\n",
        "    \"\"\"\n",
        "    with PathManager.open(os.path.join(dirname, split + \".txt\")) as f:\n",
        "        fileids = np.loadtxt(f, dtype=np.str)\n",
        "\n",
        "    # Needs to read many small annotation files. Makes sense at local\n",
        "    annotation_dirname = PathManager.get_local_path(os.path.join(dirname, \"annotations/\"))\n",
        "    dicts = []\n",
        "    for fileid in fileids:\n",
        "        anno_file = os.path.join(annotation_dirname, fileid + \".xml\")\n",
        "        jpeg_file = os.path.join(dirname, \"images/\", fileid + \".jpg\")\n",
        "\n",
        "        with PathManager.open(anno_file) as f:\n",
        "            tree = ET.parse(f)\n",
        "\n",
        "        r = {\n",
        "            \"file_name\": jpeg_file,\n",
        "            \"image_id\": fileid,\n",
        "            \"height\": int(tree.findall(\"./size/height\")[0].text),\n",
        "            \"width\": int(tree.findall(\"./size/width\")[0].text),\n",
        "        }\n",
        "        instances = []\n",
        "\n",
        "        for obj in tree.findall(\"object\"):\n",
        "            cls = obj.find(\"name\").text\n",
        "            # We include \"difficult\" samples in training.\n",
        "            # Based on limited experiments, they don't hurt accuracy.\n",
        "            # difficult = int(obj.find(\"difficult\").text)\n",
        "            # if difficult == 1:\n",
        "            # continue\n",
        "            bbox = obj.find(\"bndbox\")\n",
        "            bbox = [float(bbox.find(x).text) for x in [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]]\n",
        "            # Original annotations are integers in the range [1, W or H]\n",
        "            # Assuming they mean 1-based pixel indices (inclusive),\n",
        "            # a box with annotation (xmin=1, xmax=W) covers the whole image.\n",
        "            # In coordinate space this is represented by (xmin=0, xmax=W)\n",
        "            bbox[0] -= 1.0\n",
        "            bbox[1] -= 1.0\n",
        "            instances.append(\n",
        "                {\"category_id\": class_names.index(cls), \"bbox\": bbox, \"bbox_mode\": BoxMode.XYXY_ABS}\n",
        "            )\n",
        "        r[\"annotations\"] = instances\n",
        "        dicts.append(r)\n",
        "    return dicts\n",
        "\n",
        "\n",
        "def register_pascal_voc(name, dirname, split, year, class_names=CLASS_NAMES):\n",
        "    meta_data = DatasetCatalog.register(name, lambda: load_voc_instances(dirname, split, class_names))\n",
        "    catalog = MetadataCatalog.get(name).set(\n",
        "        thing_classes=list(class_names), dirname=dirname, year=year, split=split\n",
        "    )\n",
        "    #return meta_data, catalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRDQ-5RueApm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_meta_data, train_catalog = \n",
        "register_pascal_voc('train_data', dirname, split = 'train', year='2020', class_names=CLASS_NAMES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6vxuxfFBPlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset_dicts = DatasetCatalog.get('train_data')\n",
        "train_metadata=MetadataCatalog.get('train_data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0fewzc6Q_HM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "register_pascal_voc('valid_data', dirname, split = 'valid', year='2020', class_names=CLASS_NAMES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh8YyhiRQ9EM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_dataset_dicts = DatasetCatalog.get('valid_data')\n",
        "valid_metadata=MetadataCatalog.get('valid_data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWGoU9W9yqqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_dataset_dicts[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoJR4X629Ria",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_index = [0,7,12]\n",
        "for index in images_index:\n",
        "    img = cv2.imread(train_dataset_dicts[index][\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(train_dataset_dicts[index])\n",
        "    print('visualizing ',train_dataset_dicts[index][\"file_name\"])\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXg7w-Ou9RmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i7BguVN9RgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxdWB6f8yqtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyIQGMSyyLDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}